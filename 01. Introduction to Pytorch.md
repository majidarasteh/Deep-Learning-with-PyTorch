# Introduction to Pytorch

PyTorch is an open-source, **Python-based deep learning library** widely used for both research and production. According to Papers With Code, PyTorch has been the most widely used deep learning framework in research since 2019. Furthermore, the Kaggle Data Science and Machine Learning Survey 2022 reported that around $40%$ of respondents use PyTorch and this rate continues to grow each year. Reasons why PyTorch is popular:
1. **User-friendly interface**: Easy to learn and use
2. **Efficiency**: Optimized performance
3. **Flexibility**: Allows low-level customization while maintaining accessibility
4. **Balanced design**: Perfect blend of usability and advanced features

### The Three Core Components
PyTorch can be understood in terms of its three main components.
1. **Tensor Library**
   * **Foundation**: Extends NumPy's array-oriented programming.
   * **Key advantage**: Seamless GPU acceleration while maintaining CPU compatibility.
   * **Purpose**: Fundamental building block for all computations.
     
2. **Automatic Differentiation (autograd)**
   * **Function**: Automatically computes gradients for tensor operations.
   * **Benefit**: Simplifies backpropagation and model optimization.
   * **Impact**: Eliminates manual gradient calculation, making neural network training much easier.

3. **Deep Learning Library**
   * **Features**: Modular building blocks, pretrained models, loss functions, optimizers.
   * **Design philosophy**: Flexible and efficient components.
   * **Audience**: Caters to both researchers (flexibility) and developers (ease of use)
